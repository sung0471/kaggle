{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "source": [
    "https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Titanic Top 4% with ensemble modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "    !pip install matplotlib\n",
    "    !pip install seaborn\n",
    "    !pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "C extension: No module named 'pandas._libs.interval' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mD:\\Tool\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhashtable\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_hashtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtslib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_tslib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Tool\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\_libs\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m from pandas._libs.tslibs import (\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas._libs.interval'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2d90943667d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Tool\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;34m\"pandas from the source directory, you may need to run \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;34m\"'python setup.py build_ext --inplace --force' to build the C extensions first.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     ) from e\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m from pandas._config import (\n",
      "\u001b[1;31mImportError\u001b[0m: C extension: No module named 'pandas._libs.interval' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. load and check data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 use kaggle api : https://shakeratos.tistory.com/34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "    !pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c titanic\n",
    "\n",
    "# 403 - Forbidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "IDtest = test[\"PassengerId\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Outlier detection\n",
    "\n",
    "def detect_outliers(df, n, features):\n",
    "    \n",
    "\n",
    "    outlier_indices = []\n",
    "    \n",
    "    # iterate over columns\n",
    "    for col in features:\n",
    "        # 1st quartile 25%\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3rd quartile 75%\n",
    "        Q3 = np.percentile(df[col], 75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        \n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step)].index\n",
    "        \n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "    \n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)\n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n)\n",
    "    \n",
    "    return multiple_outliers\n",
    "\n",
    "Outliers_to_drop = detect_outliers(train, 2, ['Age','SibSp', 'Parch', 'Fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- np.percentile()   \n",
    "https://datascienceschool.net/view-notebook/1ce4880f58504891b8ab8550fe894a51/#%EC%82%AC%EB%B6%84%EC%9C%84%EC%88%98\n",
    "\n",
    "- IQR   \n",
    "https://drhongdatanote.tistory.com/30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tukey method (Tukey JW., 1977) to detect ouliers\n",
    "\n",
    "    detect ouliers which defines an interquartile range comprised between the 1st and 3rd quartile of the distribution values (IQR)\n",
    "\n",
    "    An outlier is a row that have a feature value outside the (IQR +- an outlier step).\n",
    "\n",
    "\n",
    "- 최소 2개이상 outlied 숫자 값을 가진 rows를 outliers로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[Outliers_to_drop]  # Show the outliers rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop outliers\n",
    "train = train.drop(Outliers_to_drop, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 joining train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train + test 더함\n",
    "train_len = len(train)\n",
    "dataset = pd.concat(objs=[train, test], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature engineering 하기 위해 합침"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 null 및 결측값 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 결측값 + NaNs값에 NaN으로 통일\n",
    "dataset = dataset.fillna(np.nan)\n",
    "\n",
    "# Null 값 체크\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "age, cabin : have an important part of missing values.\n",
    "\n",
    "survived : test 데이터셋에 없어서 그 부분은 결측값으로 측정됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# infos\n",
    "train.info()\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Numerial values 수치 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치 값 간의 correlation matrix\n",
    "g = sns.heatmap(train[['Survived', 'SibSp', 'Parch', 'Age', 'Fare']].corr(),\n",
    "                annot=True,fmt='.2f', cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fare 특성만 survival과 상당한 관계가 있음\n",
    "\n",
    "물론 다른 특성들이 쓸모없다는 의미는 아님\n",
    "survival과 관련있는 특성을 찾아야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parch vs Survived\n",
    "g = sns.factorplot(x=\"Parch\", y=\"Survived\", data=train, kind=\"bar\", size=6,\n",
    "                  palette=\"muted\")\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels(\"survival probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0, 3-4, 5-6 크기의 가족보다 적은 수의 가족이 더 많이 생존(1~2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age vs Survived\n",
    "g = sns.FacetGrid(train, col='Survived')\n",
    "g = g.map(sns.distplot, \"Age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나이 분포는 가우시안 분포와 같은 모습\n",
    "\n",
    "어린 승객들이 많이 survived\n",
    "60-80대 승객들이 덜 survived\n",
    "\n",
    "- Age와 생존자는 상관관계는 없지만, 연령대에 따라 생존 가능성이 다름을 알 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distribution\n",
    "g = sns.kdeplot(train['Age'][(train['Survived'] == 0) & (train['Age'].notnull())], color=\"Red\", shade=True)\n",
    "g = sns.kdeplot(train['Age'][(train['Survived'] == 1) & (train['Age'].notnull())], ax=g, color=\"Blue\", shade=True)\n",
    "g.set_xlabel(\"Age\")\n",
    "g.set_ylabel('Age')\n",
    "g = g.legend([\"Not Survived\", \"Survived\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0-5세 구간에서 생존자 그래프가 두드러짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Fare'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중앙값으로 채움\n",
    "dataset['Fare'] = dataset['Fare'].fillna(dataset['Fare'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값이 1개이기 때문에 예측에 큰 영향이 없을 것으로 예상   \n",
    "-> 중앙값으로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fare 분포\n",
    "# skew() : 확률 분포의 비대칭도\n",
    "# https://ko.wikipedia.org/wiki/%EB%B9%84%EB%8C%80%EC%B9%AD%EB%8F%84\n",
    "g = sns.distplot(dataset['Fare'], color='m', label='Skewness : %.2f'%(dataset['Fare'].skew()))\n",
    "g = g.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fare 분포가 많이 비대칭형태임 -> 매우 높은 값에 가중치가 과하게 매겨질 수 있음\n",
    "\n",
    "log를 씌워 비대칭성 줄여야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Fare\"] = dataset['Fare'].map(lambda i:np.log(i) if i > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.distplot(dataset['Fare'], color='b', label='Skewness : %.2f'%(dataset['Fare'].skew()))\n",
    "g = g.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log 변환으로 비대칭성이 많이 줄어듦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 범주형 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(x=\"Sex\", y=\"Survived\", data=train)\n",
    "g = g.set_ylabel(\"Survival Probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 성별 기준 생존율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"Sex\", \"Survived\"]].groupby('Sex').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 명백하게 남성의 생존율이 떨어짐\n",
    "- 성별은 생존율 예측에 중요한 역할일 것으로 예상\n",
    "- 영화에서도 탈출상황에서 \"여자와 어린이 먼저\"라는 대사가 나온걸로 기억함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pclass vs Survived\n",
    "g = sns.factorplot(x=\"Pclass\", y='Survived', data=train, kind='bar', size=6,\n",
    "                  palette='muted')\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels('survival probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pclass 가 높을수록 생존율이 높음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.factorplot(x=\"Pclass\", y='Survived', hue='Sex', data=train,\n",
    "                  size=6, kind='bar', palette='muted')\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels('survival probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 첫 번째 클래스가 다른 두 클래스보다 생존율이 높음\n",
    "- 남성/여성을 분리해서 보아도 그 경향이 유지됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Embarked'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Embarked'][dataset['Embarked'] == 'S'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Embarked'] = dataset['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결손값이 2개이므로, 가장 빈도수가 많은 값을 넣음 = S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.factorplot(x='Embarked', y='Survived', data=train,\n",
    "                   size=6, kind='bar', palette='muted')\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels('survival probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cherbourg(C)에서 온 승객들의 생존율이 높음\n",
    "\n",
    "- 저자의 가정 : Cherbourg에서 온 사람들이 first class에 많은 부분을 차지할 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pclass vs Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.factorplot('Pclass', col='Embarked', data=train,\n",
    "                  size=6, kind='count', palette='muted')\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실제로는, Southamton(S), Queenstown(Q)에서 온 순으로 3 class를 많이 차지함\n",
    "- Cherbourg 승객들은 생존율이 높은 1 class가 상당 수 차지하고 있음\n",
    "- 하지만, 1 class의 생존율이 높은지는 설명할 수 없음   \n",
    "\n",
    "\n",
    "- 가정 : 1 class 승객들이 영향력?으로 탈출시에 우선되지 않았을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 결손값 채우기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전체 데이터셋에서 256개 결손값 존재\n",
    "\n",
    "\n",
    "- it is preferable to keep the age feature and to impute the missing values.\n",
    "\n",
    "- 이를 해결하기 위해, Age와 상관관계있는 특성들을 찾을 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.factorplot(y='Age', x='Sex', data=dataset, kind='box')\n",
    "g = sns.factorplot(y='Age', x='Sex', hue=\"Pclass\", data=dataset, kind='box')\n",
    "g = sns.factorplot(y='Age', x='Parch', data=dataset, kind='box')\n",
    "g = sns.factorplot(y='Age', x='SibSp', data=dataset, kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 남성, 여성은 Age 분포와 유사\n",
    "\n",
    "\n",
    "- Pclass의 경우, 1, 2, 3 class 순으로 연령대가 낮아짐\n",
    "- 부모/자식이 많을 수록 연령대가 높음\n",
    "- 형제/배우자가 많을수록 연령대가 낮음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성별 데이터 수치로 변환\n",
    "dataset['Sex'] = dataset['Sex'].map({'male':0, 'female':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.heatmap(dataset[['Age', 'Sex', 'SibSp', 'Parch', 'Pclass']].corr(), cmap='BrBG',\n",
    "               annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 상관계수 지도(map) : Pclass, SibSp, Parch순으로 Age는 음의 상관관계가 내림차순임\n",
    "\n",
    "\n",
    "- Parch 그래프는 Parch가 크면 평균 Age가 높은데, 상관계수는 반대임\n",
    "- SibSp, Parch, Pclass를 Age 결손값을 채우는데 활용\n",
    "\n",
    "\n",
    "- Pclass, Parch, SibSp에 따라 유사한 열들의 중간값 age로 채움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age 결측값 채움\n",
    "index_NaN_age = list(dataset['Age'][dataset['Age'].isnull()].index)\n",
    "\n",
    "for i in index_NaN_age:\n",
    "    age_med = dataset[\"Age\"].median()\n",
    "    age_pred = dataset[\"Age\"][\n",
    "        ((dataset['SibSp'] == dataset.iloc[i]['SibSp']) & \n",
    "        (dataset['Parch'] == dataset.iloc[i]['Parch']) &\n",
    "        (dataset['Pclass'] == dataset.iloc[i]['Pclass']))].median()\n",
    "    if not np.isnan(age_pred):\n",
    "        dataset['Age'].iloc[i] = age_pred\n",
    "    else:\n",
    "        dataset['Age'].iloc[i] = age_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.factorplot(x='Survived', y='Age', data=train, kind='box')\n",
    "g = sns.factorplot(x='Survived', y='Age', data=train, kind='violin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 생존자와 사망자 나이의 중앙값이 차이가 없음\n",
    "\n",
    "\n",
    "- violin 그래프를 보면, 어린 승객들의 생존율이 여전히 높음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature engeering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name/Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Name'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이름 특성들은 승객들의 직함(title)을 포함함\n",
    "\n",
    "\n",
    "- 구별되는 직함을 가진 일부 승객들은 탈출에 더 선호되었을 것\n",
    "- Since some passenger with distingused title may be preferred during the evacuation, it is interesting to add them to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이름에서 직함을 추출\n",
    "dataset_title = [i.split(',')[1].split('.')[0].strip() for i in dataset[\"Name\"]]\n",
    "dataset['Title'] = pd.Series(dataset_title)\n",
    "dataset['Title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.countplot(x='Title', data=dataset)\n",
    "g = plt.setp(g.get_xticklabels(), rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 17개의 직함이 있음\n",
    "- 대부분 데이터가 거의 없어 4개 그룹으로 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countess: 백작부인, Mlle : 불어, 미혼여성, Mme : 불어, 미혼여성\n",
    "# Master : 남자아이\n",
    "dataset['Title'] = dataset['Title'].replace(\n",
    "    ['Lady', 'the Countess', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev',\n",
    "    'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "dataset['Title'] = dataset['Title'].map({'Master':0, 'Miss':1, 'Ms':1, 'Mme': 1,\n",
    "                                        'Mlle':1, 'Mrs':1, 'Mr':2, 'Rare':3})\n",
    "dataset['Title'] = dataset['Title'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.countplot(dataset['Title'])\n",
    "g = g.set_xticklabels(['Master', 'Miss/Ms/Mme/Mlle/Mrs', 'Mr', 'Rare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.factorplot(x='Title', y='Survived', data=dataset, kind='bar')\n",
    "g = g.set_xticklabels(['Master', 'Miss-Mrs', 'Mr', 'Rare'])\n",
    "g = g.set_ylabels('survival probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 특이하게 Rare 범주에 속한 승객들의 생존율이 높은 편임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(labels=['Name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 가족구성원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 가족구성원 수가 많으면 생존율이 떨어진다 상상할 수 있음 (형제, 부모를 구해야 해서)\n",
    "- Fize 라는 특성을 만듬 = (SibSp + Parch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Fsize'] = dataset['SibSp'] + dataset['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.factorplot(x='Fsize', y='Survived', data=dataset)\n",
    "g = g.set_ylabels('Survival Probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fsize가 큰 경우 생존율이 낮다\n",
    "- 해당 값을 4개의 범주형 값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Single'] = dataset['Fsize'].map(lambda s: 1 if s == 1 else 0)\n",
    "dataset['SmallF'] = dataset['Fsize'].map(lambda s: 1 if s == 2 else 0)\n",
    "dataset['MedF'] = dataset['Fsize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n",
    "dataset['LargeF'] = dataset['Fsize'].map(lambda s:1 if 5 <= s else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.factorplot(x='Single', y='Survived', data=dataset, kind='bar')\n",
    "g = g.set_ylabels('Survival Probability')\n",
    "g = sns.factorplot(x='SmallF', y='Survived', data=dataset, kind='bar')\n",
    "g = g.set_ylabels('Survival Probability')\n",
    "g = sns.factorplot(x='MedF', y='Survived', data=dataset, kind='bar')\n",
    "g = g.set_ylabels('Survival Probability')\n",
    "g = sns.factorplot(x='LargeF', y='Survived', data=dataset, kind='bar')\n",
    "g = g.set_ylabels('Survival Probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- small, medium 가족수 : 생존율이 더 높음\n",
    "- single, large 가족수 : 생존율이 더 낮음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, columns=['Title'])\n",
    "dataset = pd.get_dummies(dataset, columns=['Embarked'], prefix='Em')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 현재 특성 수는 22개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Cabin'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Cabin'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Cabin'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Cabin\"][dataset[\"Cabin\"].notnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in dataset['Cabin'] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cabin이 없는 경우 X로 처리\n",
    "- cabin의 첫글자는 desk를 가리킴 / Titanic에서 승객의 위치를 가리킬 수 있음   \n",
    "    -> 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.countplot(dataset[\"Cabin\"],order=['A','B','C','D','E','F','G','T','X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.factorplot(y=\"Survived\",x=\"Cabin\",data=dataset,\n",
    "                   kind=\"bar\",order=['A','B','C','D','E','F','G','T','X'])\n",
    "g = g.set_ylabels(\"Survival Probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cabin 보유한 승객 수가 적어, 생존확률의 표준편차가 큼   \n",
    "    -> cabin으로는 승객 생존율을 구분할 수 없음\n",
    "- cabin을 보유한 승객이 아닌 승객(X)보다 생존율이 높음   \n",
    "    -> B, C, D, E, F만 맞다고 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, columns=['Cabin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Ticket\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 같은 접두어를 공유하는 티겟들은 같은 cabin을 예약했을 가능성이 있음\n",
    "- 그래서, 배에서 실제 위치를 나타내는 지표가 될 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 같은 접두어를 가진 티켓들은 비슷한 class와 생존율을 가질 것임\n",
    "- 그래서, Ticket 값들은 접두어만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ticket = []\n",
    "for i in list(dataset.Ticket):\n",
    "    if not i.isdigit():\n",
    "        Ticket.append(i.replace('.', '').replace('/','').strip().split(' ')[0])\n",
    "        # take prefix\n",
    "    else:\n",
    "        Ticket.append('X')\n",
    "\n",
    "dataset['Ticket'] = Ticket\n",
    "dataset['Ticket'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, columns = ['Ticket'], prefix='T')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Pclass, PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Pclass\"] = dataset[\"Pclass\"].astype(\"category\")\n",
    "dataset = pd.get_dummies(dataset, columns = [\"Pclass\"],prefix=\"Pc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(labels = [\"PassengerId\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = dataset[:train_len]\n",
    "test = dataset[train_len:]\n",
    "test.drop(labels=[\"Survived\"],axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Survived\"] = train[\"Survived\"].astype(int)\n",
    "\n",
    "Y_train = train[\"Survived\"]\n",
    "\n",
    "X_train = train.drop(labels = [\"Survived\"],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Simple modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1 cross validate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10개의 분류기를 비교하고, kfold 교차검증절차로 평균 정확도를 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVC\n",
    "- Decision Tree\n",
    "- AdaBoost\n",
    "- Random Forest\n",
    "- Extra Trees\n",
    "- Gradient Boosting\n",
    "- Multiple layer perceprton (neural network)\n",
    "- KNN\n",
    "- Logistic regression\n",
    "- Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kfold 교차검증 모델\n",
    "kfold = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 2\n",
    "classifiers = []\n",
    "classifiers.append(SVC(random_state=random_state))\n",
    "classifiers.append(DecisionTreeClassifier(random_state=random_state))\n",
    "classifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\n",
    "classifiers.append(RandomForestClassifier(random_state=random_state))\n",
    "classifiers.append(ExtraTreesClassifier(random_state=random_state))\n",
    "classifiers.append(GradientBoostingClassifier(random_state=random_state))\n",
    "classifiers.append(MLPClassifier(random_state=random_state))\n",
    "classifiers.append(KNeighborsClassifier())\n",
    "classifiers.append(LogisticRegression(random_state = random_state))\n",
    "classifiers.append(LinearDiscriminantAnalysis())\n",
    "\n",
    "cv_results = []\n",
    "for classifier in classifiers :\n",
    "    cv_results.append(cross_val_score(classifier, X_train, y = Y_train, \n",
    "                                      scoring='accuracy', cv=kfold, n_jobs=4))\n",
    "\n",
    "cv_means = []\n",
    "cv_std = []\n",
    "for cv_result in cv_results:\n",
    "    cv_means.append(cv_result.mean())\n",
    "    cv_std.append(cv_result.std())\n",
    "\n",
    "cv_res = pd.DataFrame(\n",
    "    {\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\n",
    "     \"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\"RandomForest\",\"ExtraTrees\",\n",
    "                  \"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\n",
    "                  \"LogisticRegression\",\"LinearDiscriminantAnalysis\"]})\n",
    "\n",
    "g = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, \n",
    "                palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\n",
    "g.set_xlabel(\"Mean Accuracy\")\n",
    "g = g.set_title(\"Cross validation scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
